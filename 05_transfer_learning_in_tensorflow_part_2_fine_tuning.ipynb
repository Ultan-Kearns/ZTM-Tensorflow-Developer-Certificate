{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e2dfd9-d45a-48f1-8420-8883e0c632dc",
   "metadata": {},
   "source": [
    "# Transfer Learning with Tensorflow part 2: Fine Tuning\n",
    "\n",
    "In the previous notebook, we covered transfer learning feature extraction. Now it's time to learn a new kind of tranfer learning: fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b1cf5-1876-47f8-a42d-1585038ad8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "!nvidia-smi\n",
    "tf.config.list_physical_devices\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd583dc-d852-4222-8764-72cf0e3ac489",
   "metadata": {},
   "source": [
    "## Creating helper function\n",
    "In previous notebooks, we've created a bunch of helper functions, now we could rewrite them all, however, this is tedious.\n",
    "\n",
    "Always a good idea to use helper functions remember the don't repeat yourself rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae90ee3-1423-450d-9be3-dabe5a3b23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install wget\n",
    "!pip install scikit-learn\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf37f2-3367-4e4b-bb3b-4b6c0dfb94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions we're going to use in the notebook\n",
    "from helper_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968e93c-8ec6-489b-8503-91d32e6e8821",
   "metadata": {},
   "source": [
    "> **Note** if you're running this notebook in Colab, the runtime may time out.  When the runtime runs out colab will delete the helper function so will need to redownload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20f253-d14b-4abe-b253-a258d71234d4",
   "metadata": {},
   "source": [
    "## Let's get some data\n",
    "\n",
    "This time we're going to see how we can use the pre-trained models within tf.keras.applications and apply them to our own problem(recognizing images of food).\n",
    "\n",
    "link: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c5450-840b-494e-9dbc-810ba2995729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10% of training data of 10 classes of Food101\n",
    "if(not os.path.exists(\"10_food_classes_10_percent.zip\")):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
    "    unzip_data(\"10_food_classes_10_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377ded6-9a74-4afc-a9b1-32d65e2f4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout how many images and sub directories are in our dataset\n",
    "walk_through_dir(\"10_food_classes_10_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9deca-89fe-4f94-b2f8-f19aae71f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test directory path\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244af4af-1055-4365-8536-f9591e363a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                            image_size=IMG_SIZE,\n",
    "                                                                           label_mode=\"categorical\",\n",
    "                                                                           batch_size = BATCH_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                          image_size=IMG_SIZE,\n",
    "                                                                          label_mode=\"categorical\",\n",
    "                                                                          batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b34622-fd57-4b55-8886-d1cf698653aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be171d-9a6c-4f07-a37d-e05abebce8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_10_percent.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c97e6-a9b6-437f-b72f-6fd1fecc016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See an example of batch of data\n",
    "for images,labels in train_data_10_percent.take(1):\n",
    "    print(images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf63e14-21c5-4591-b830-cbcb67ce4862",
   "metadata": {},
   "source": [
    "## Model 0: building a transfer learning model using the Keras Functional API\n",
    "\n",
    "The sequential API is straight-forward, it runs our layers in sequential order.\n",
    "\n",
    "But the functional API gives us more flexibility in desiging our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872052d1-9a26-4bbc-8a97-fa6b5c5034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "efficentnet_b0 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=10,\n",
    "    classifier_activation='softmax',\n",
    ")\n",
    "\n",
    "efficentnet_b0.trainable = False\n",
    "\n",
    "# create inputs for model\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3),name=\"input_layer\")\n",
    "# normalize, needed for some architectures\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "x = efficentnet_b0(inputs)\n",
    "print(f\"Shape after passing inputs through the base model:{x.shape}\")\n",
    "# average pool the outputs of base model(aggregate most important information, reduce computational expenses)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D:{x.shape}\")\n",
    "# create output activation layer\n",
    "outputs = tf.keras.layers.Dense(10,activation=\"softmax\",name=\"output_layer\")(x)\n",
    "# combine inputs and outputs into model\n",
    "model_0 = tf.keras.Model(inputs,\n",
    "                   outputs)\n",
    "\n",
    "model_0.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                       loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                       metrics=[\"accuracy\"])\n",
    "history_model_0 = model_0.fit(train_data_10_percent,epochs=5,validation_data=test_data,validation_steps=int(0.25*len(test_data)),callbacks=[create_tensorboard_callback(dir_name=\"transfer learning\",experiment_name=\"10_percent_feature_extraction\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460d880-bea8-43a8-a4c6-ec305187b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62dea3-4e5a-489d-8081-c0619441029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers in our base model\n",
    "for layer_number, layer in enumerate(efficentnet_b0.layers):\n",
    "    print(f\"Layer number:{layer_number} layer name:{layer.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf681d6-c45f-46ba-af03-0809b3751c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of base model\n",
    "efficentnet_b0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a9ab0-000c-4d45-94fa-782f900be854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885286a4-ebe1-4c82-b14a-f170224c660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out models training curves\n",
    "plt.show(plot_loss_curves(history_model_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1c4ce-fc04-48e3-8d8d-f84d9d455715",
   "metadata": {},
   "source": [
    "## Getting a feature vector from a trained model \n",
    "Let's demonstrate the Global Average Pooling 2d layer...\n",
    "We have a tensor after our model goes through `base+model` of shape (None,7,7,1280).\n",
    "\n",
    "But then when it passes through GlobalAveragePooling2D, it turns into (None,1280)\n",
    "\n",
    "Let's use a similar shaped tensor of (1,4,4,3) and then pass it to GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f09c4-d445-4625-b68e-6c8a520a58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "input_shape =(1,4,4,3)\n",
    "#create a random tensor\n",
    "tf.random.set_seed(42)\n",
    "input_tensor=tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n{input_tensor}\\n\")\n",
    "\n",
    "# Pass the random tensor through a random global average pooling 2D layer\n",
    "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "print(f\"2D global average pooled random tensor:\\n{global_average_pooled_tensor}\\n\")\n",
    "\n",
    "# Check the shape of the different tensors\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of global average pooled 2D: {global_average_pooled_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfee266-a798-48e5-b2e8-3d7724b8a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replicate the GlobalAveragePool2D layer\n",
    "tf.reduce_mean(input_tensor,axis=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86cbbc2-aeac-4d5f-ae33-e337653e8cc9",
   "metadata": {},
   "source": [
    "**Practice** Try to do the same with the above two cells but this time use `GlobalMaxPool2D`... and see what happens\n",
    "\n",
    "**Note** Onen of the reasons feature extraction transfer learning is named how it is is because what often happens is a pretrained model outputs a feature vector - a learned representation of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df934a-31f7-42ac-b8f9-7fbd2085ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_pool_tensor = tf.keras.layers.GlobalMaxPool2D()(input_tensor) \n",
    "print(global_max_pool_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3613a67-8f88-4e98-b723-51c91fbbb84b",
   "metadata": {},
   "source": [
    "## Running a series of transfer learning experiments\n",
    "\n",
    "We've seen the incredible results transfer learning can get with only 10% of the training data, but how does it go with only 1% of the training data... how about we set up a bunch of experiments to find out:\n",
    "\n",
    "1. `model_1` - use feature extraction transfer learning iwth 1% of the training data with augmentation\n",
    "2. `model_2` - use feature extraction transfer learning with 10% of the training data with data augmentation\n",
    "3. `model_3` - use fine-tuning transfer learning with 10% of the training data which will also use data augmentation\n",
    "4. `model_4`- use fine-tuning transfer learning on 100% of the training data with data augmentation.\n",
    "   \n",
    "**Note**: throughout all experiments we will use the same test dataset, so that we can be consistent in evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d112731-c6ee-41ca-9133-22c9bd6ffaf8",
   "metadata": {},
   "source": [
    "## Getting and preprocessing data for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98019ce9-65c6-4c81-80b0-a7ac8bd83604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    " \n",
    "if not os.path.exists(\"./10_food_classes_1_percent.zip\"):\n",
    "    !curl --output \"10_food_classes_1_percent.zip\" -X GET \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\"\n",
    "    unzip_data(\"./10_food_classes_1_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfdb19-bd1b-4252-bcc2-8c7ad55f1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dirs\n",
    "train_dir_1_percent = \"10_food_classes_1_percent/train\"\n",
    "test_dir = \"10_food_classes_1_percent/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73731ef3-fbc2-49e9-8458-5ba689380774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are we working with\n",
    "walk_through_dir(\"10_food_classes_1_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d6d40-3b2f-487d-ac66-1d38a4c16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data loaders\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
    "                                                                          label_mode=\"categorical\",\n",
    "                                                                          image_size=IMG_SIZE,\n",
    "                                                                          batch_size=BATCH_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7191eb7-f04d-44d2-aaa3-309d564cfeee",
   "metadata": {},
   "source": [
    "# Adding data augmentation right into the model\n",
    "\n",
    "\n",
    "To add data augmentation right into our models, we can use the layers inside:\n",
    "\n",
    "+ `tf.keras.layers.experimental.preprocessing()`\n",
    "\n",
    "Benefits of data augmentation\n",
    "\n",
    "+ More data - model may be better able to generalize\n",
    "+ preprocessing of images(augmenting them) happens on the GPU which is far faster for this type of problem than the CPU\n",
    "+ Image data augmentation only happens during training so we can still export out model and use it elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab61aef-da7e-4ace-bc3b-0954e8f3913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create data augmentation stage with horizontal flipping, rotations, zooms,etc.\n",
    "    \n",
    "data_augmentation = keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomHeight(0.2),\n",
    "    tf.keras.layers.RandomWidth(0.2),\n",
    "    # tf.keras.layers.Rescaling(1./255) - keep for models like resnet50V2 but for efficientnet it has rescaling built in\n",
    "],name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13754d23-7a69-4f32-a412-a56270242064",
   "metadata": {},
   "source": [
    "### visualize our data augmentation layer(and check the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41902399-93f9-4074-8c99-9c7fb802ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a random image and compare it to the augmented version\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "target_class = random.choice(train_data_1_percent.class_names)\n",
    "target_dir = \"10_food_classes_1_percent/train/\" + target_class\n",
    "random_image = random.choice(os.listdir(target_dir))\n",
    "random_image_path = target_dir + \"/\" + random_image\n",
    "print(target_dir)\n",
    "# read in random image + plot\n",
    "img = mpimg.imread(random_image_path)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Original random image from class {target_class}\")\n",
    "plt.axis(False)\n",
    "# now let's plot augmented random image\n",
    "augmented_image = data_augmentation(img)\n",
    "plt.figure()\n",
    "plt.show()\n",
    "plt.title(f\"Augmented random image from class {target_class}\")\n",
    "plt.axis(False)\n",
    "plt.imshow(tf.squeeze(augmented_image / 255.))\n",
    "plt.show()\n",
    "print(img)\n",
    "print(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca23eb5-f688-43b7-9945-be550defaf35",
   "metadata": {},
   "source": [
    "## Model 1: Feature extraction on transfer learning on 1% of the data using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45026ae6-e164-45d7-b5e5-a8a05cc491c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input shape and base model freezing the base model layers\n",
    "input_shape=(224,224,3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable=False\n",
    "\n",
    "# Crete input layer\n",
    "inputs = layers.Input(shape=input_shape,name=\"input_layer\")\n",
    "\n",
    "# add in data augmentation Sequential model as layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# GIve base_model the inputs(after augmentation) & don't train it\n",
    "\n",
    "x = base_model(x,training=False)\n",
    "\n",
    "# Pool output features of the base model\n",
    "\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_avg_pooling_layer\")(x)\n",
    "\n",
    "# Put a dense layer on as the output\n",
    "outputs = layers.Dense(10,activation=\"softmax\",name=\"ouput_layer\")(x)\n",
    "\n",
    "# Make a model using inputs and outpus\n",
    "\n",
    "model_1 = keras.Model(inputs,outputs)\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "# Fit the model\n",
    "history_1_percent = model_1.fit(train_data_1_percent,\n",
    "                               epochs=5,\n",
    "                               steps_per_epoch=len(train_data_1_percent),\n",
    "                               validation_data=test_data,\n",
    "                               validation_steps=int(0.25*len(test_data)),\n",
    "                               callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",experiment_name=\"1_percent_data_aug\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout model 1 summary\n",
    "model_1.summary()\n",
    "history_1_percent.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on full data set\n",
    "results_1_percent_data_aug = model_1.evaluate(test_data)\n",
    "results_1_percent_data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves for data augmentation with 1 percent\n",
    "plt.show(plot_loss_curves(history_1_percent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Feature extraction on transfer learning on 10% of the data using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_10_percent = \"./10_food_classes_10_percent/train\"\n",
    "test_dir_10_percent = \"./10_food_classes_10_percent/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                               image_size=IMG_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir_10_percent,\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                               image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are in dir\n",
    "walk_through_dir(\"10_food_classes_10_percent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomRotation(0.2)\n",
    "    # if using another model rescaling may be needed as efficientNet has rescaling built in\n",
    "])\n",
    "# Setup input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input shape and base model freezing the base model layers\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_shape=(224,224,3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable=False\n",
    "\n",
    "# Crete input layer\n",
    "inputs = layers.Input(shape=input_shape,name=\"input_layer\")\n",
    "\n",
    "# add in data augmentation Sequential model as layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Give base_model the inputs(after augmentation) & don't train it\n",
    "x = base_model(x,training=False)\n",
    "\n",
    "# Pool output features of the base model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_avg_pooling_layer\")(x)\n",
    "\n",
    "# Put a dense layer on as the output\n",
    "outputs = layers.Dense(10,activation=\"softmax\",name=\"ouput_layer\")(x)\n",
    "\n",
    "# Make a model using inputs and outpus\n",
    "model_2 = keras.Model(inputs,outputs)\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "# Fit the model\n",
    "history_10_percent = model_2.fit(train_data,\n",
    "                               epochs=5,\n",
    "                               steps_per_epoch=len(train_data),\n",
    "                               validation_data=test_data,\n",
    "                               validation_steps=int(0.25*len(test_data)),\n",
    "                               callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",experiment_name=\"10_percent_data_aug\")])\n",
    "data_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model checkpoint callback\n",
    "\n",
    "The ModelCheckpoint callback intermediately saves our model(full model or just weights) during training.  This is useful so we can pause training and come back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path='./ten_percent_model_checkpoints-weights/checkpoint.ckpt'\n",
    "\n",
    "# Create a model checkpoint callback to save weights\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch', # save every epoch\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_10_percent = model_2.fit(train_data,\n",
    "                               epochs=5,\n",
    "                               steps_per_epoch=len(train_data),\n",
    "                               validation_data=test_data,\n",
    "                               validation_steps=int(0.25*len(test_data)),\n",
    "                               callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",experiment_name=\"10_percent_data_aug\"),model_checkpoint_callback])\n",
    "data_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were model 0 results\n",
    "model_0.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model 2 results on all test data \n",
    "results_10_percent_data_aug = model_2.evaluate(test_data)\n",
    "results_10_percent_data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model loss curves\n",
    "plt.show(plot_loss_curves(history_10_percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
