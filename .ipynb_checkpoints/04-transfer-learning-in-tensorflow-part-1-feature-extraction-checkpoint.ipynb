{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3d993f-469e-4c66-9555-55af951f9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 22:43:32.481999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 22:43:33.116652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0daa54a-dc4c-4f03-9615-c6c74c44ebbe",
   "metadata": {},
   "source": [
    "# Transfer learning with tensorflow part 1: feature extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
    "\n",
    "There are two main benefits:\n",
    "\n",
    "1. Can leverage the existing neural network architecture proven to work on problems similar to our own\n",
    "2. Can leverage a working neural architectures which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f4def-b564-45f4-80e7-704676ef69d0",
   "metadata": {},
   "source": [
    "## Downloading and becoming one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4a2d4c-f73a-4c26-8f97-bbea67408f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data(10% of 10 food classes file)\n",
    "import zipfile \n",
    "import os\n",
    "\n",
    "# Unzip downloaded file\n",
    "if not \"10_food_classes_10_percent.zip\" in os.listdir(\"./\"):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
    "    zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4733c2b9-dcaa-4c88-97f1-37c2edc96a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 in 10_food_classes_10_percent\n",
      "There are 10 directories and 0 in 10_food_classes_10_percent/test\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/fried_rice\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/ice_cream\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/ramen\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/hamburger\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/sushi\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/chicken_curry\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/grilled_salmon\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/pizza\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/steak\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/chicken_wings\n",
      "There are 10 directories and 0 in 10_food_classes_10_percent/train\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/fried_rice\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/ice_cream\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/ramen\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/hamburger\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/sushi\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/chicken_curry\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/grilled_salmon\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/pizza\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/steak\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/chicken_wings\n"
     ]
    }
   ],
   "source": [
    "# walk through 10% data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} in {dirpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf396b-b6bd-4739-9df2-f316a8ca71b9",
   "metadata": {},
   "source": [
    "## Creating data loaders(preparing the data)\n",
    "We'll use the `ImageDataGenerator` class to load our images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c682949-4d60-4f89-a3b7-9635523fe6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:\n",
      "Found 750 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "EPOCHS = 5\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\"\n",
    "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training Images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size=IMAGE_SHAPE,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          class_mode=\"categorical\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=IMAGE_SHAPE,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f167-0d4f-40ab-9dbc-e28e358e80a2",
   "metadata": {},
   "source": [
    " ## Setting up callbacks(things to run whilst our model trains)\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training.  Some of the most popular callbacks:\n",
    "\n",
    "* Tracking experiments with the Tensorboard callback\n",
    "* Model checkpoint with the ModelCheckpoint callback\n",
    "* Stopping a model from training(before it takes too long and overfits) with Earlystopping Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10da1bf4-8ea4-4ffc-9cfe-353820f198d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tensorboard callback (functionized because we need to create a new one for each model)\n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name,experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "    print(f\"Saving TensorBoard log files to:{log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32275c-cb16-420f-b868-8e76c687b4ee",
   "metadata": {},
   "source": [
    "## Creating models using tensorflow hub\n",
    "\n",
    "In the past we've used Tensorflow to create our own models layer by layer from scratch.\n",
    "\n",
    "Now we're going to do a similar process, except the majority of our model's layers are going to come from Tensorflow Hub.\n",
    "\n",
    "We can access pretrained models from https://www.tensorflow.org/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd4725-0ffe-48e9-81c9-78088ac164d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 23:12:40.006033: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.028996: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.029223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.030570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.030739: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.030889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.104292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.104563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.104724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 23:12:40.104882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11992 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:09:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    " # https://www.kaggle.com/models/tensorflow/efficientnet/tensorFlow2/b0-feature-vector/1?tfhub-redirect=true\n",
    "import tensorflow_hub as hub\n",
    "m = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\",\n",
    "                   trainable=False),  # Can be True, see below.\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "m.build([None, expect_img_size, expect_img_size, 3])  # Batch input shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685903b-fb36-4527-92d8-a6571e3e81c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
