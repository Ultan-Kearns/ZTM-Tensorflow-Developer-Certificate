{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3d993f-469e-4c66-9555-55af951f9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 00:03:26.111136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-12 00:03:26.127658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-12 00:03:26.132923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-12 00:03:26.145365: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726099407.320504      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726099407.328378      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726099407.330492      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# necessary as keras 3 has some issues with hublayers\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0daa54a-dc4c-4f03-9615-c6c74c44ebbe",
   "metadata": {},
   "source": [
    "# Transfer learning with tensorflow part 1: feature extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
    "\n",
    "There are two main benefits:\n",
    "\n",
    "1. Can leverage the existing neural network architecture proven to work on problems similar to our own\n",
    "2. Can leverage a working neural architectures which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f4def-b564-45f4-80e7-704676ef69d0",
   "metadata": {},
   "source": [
    "## Downloading and becoming one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4a2d4c-f73a-4c26-8f97-bbea67408f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data(10% of 10 food classes file)\n",
    "import zipfile \n",
    "import os\n",
    "\n",
    "# Unzip downloaded file\n",
    "if not \"10_food_classes_10_percent.zip\" in os.listdir(\"./\"):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
    "    zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4733c2b9-dcaa-4c88-97f1-37c2edc96a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 in 10_food_classes_10_percent\n",
      "There are 10 directories and 0 in 10_food_classes_10_percent/train\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/ramen\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/grilled_salmon\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/chicken_curry\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/sushi\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/pizza\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/ice_cream\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/steak\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/hamburger\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/fried_rice\n",
      "There are 0 directories and 75 in 10_food_classes_10_percent/train/chicken_wings\n",
      "There are 10 directories and 0 in 10_food_classes_10_percent/test\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/ramen\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/grilled_salmon\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/chicken_curry\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/sushi\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/pizza\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/ice_cream\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/steak\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/hamburger\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/fried_rice\n",
      "There are 0 directories and 250 in 10_food_classes_10_percent/test/chicken_wings\n"
     ]
    }
   ],
   "source": [
    "# walk through 10% data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} in {dirpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf396b-b6bd-4739-9df2-f316a8ca71b9",
   "metadata": {},
   "source": [
    "## Creating data loaders(preparing the data)\n",
    "We'll use the `ImageDataGenerator` class to load our images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c682949-4d60-4f89-a3b7-9635523fe6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:\n",
      "Found 750 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "EPOCHS = 5\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\"\n",
    "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training Images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size=IMAGE_SHAPE,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          class_mode=\"categorical\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=IMAGE_SHAPE,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f167-0d4f-40ab-9dbc-e28e358e80a2",
   "metadata": {},
   "source": [
    " ## Setting up callbacks(things to run whilst our model trains)\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training.  Some of the most popular callbacks:\n",
    "\n",
    "* Tracking experiments with the Tensorboard callback\n",
    "* Model checkpoint with the ModelCheckpoint callback\n",
    "* Stopping a model from training(before it takes too long and overfits) with Earlystopping Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10da1bf4-8ea4-4ffc-9cfe-353820f198d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tensorboard callback (functionized because we need to create a new one for each model)\n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name,experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "    print(f\"Saving TensorBoard log files to:{log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32275c-cb16-420f-b868-8e76c687b4ee",
   "metadata": {},
   "source": [
    "## Creating models using tensorflow hub\n",
    "\n",
    "In the past we've used Tensorflow to create our own models layer by layer from scratch.\n",
    "\n",
    "Now we're going to do a similar process, except the majority of our model's layers are going to come from Tensorflow Hub.\n",
    "\n",
    "We can access pretrained models from https://www.tensorflow.org/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6497f20-979c-4399-9a6d-9a089ee3afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296c31f2-b1a8-4606-8d43-5eb8619375b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a create_model() function to create a model from a URL\n",
    "\n",
    "def create_model(model_url,num_classes=10):\n",
    "    \"\"\"\n",
    "    Takes a tensorflow hub URL and creates a keras sequential model with it\n",
    "\n",
    "    Args:\n",
    "        model_url (str): A tensorflow hub feature extraction URL\n",
    "        num_classes (int): Number of output neurons in the output layer,\n",
    "        should be equal to number of target classes, default 10.\n",
    "\n",
    "    Returns:\n",
    "        An uncompiled Keras Sequential model with model_url as feature extractor\n",
    "        layer and Dense output layer with num_classes output neurons\n",
    "    \"\"\"\n",
    "\n",
    "    # Download the pretrained model and save it as keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,trainable=False,input_shape=IMAGE_SHAPE+(3,))\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        tf.keras.layers.Dense(num_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f40145-4e6d-4023-9533-2edd4d8bfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 50 V2 feature vector\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "# Original: EfficientNetB0 feature vector (version 1)\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "\n",
    "# # New: EfficientNetB0 feature vector (version 2)\n",
    "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692db71-f90d-4c58-9bed-07de5ab7a50d",
   "metadata": {},
   "source": [
    "### Creating ResNet Tensorflow Hub Feature Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d31365-0de0-44d2-9c12-b820e2d0124b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_hub' has no attribute 'KerasLayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create resnet model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet_url\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m resnet_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m resnet_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_url, num_classes)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mTakes a tensorflow hub URL and creates a keras sequential model with it\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    layer and Dense output layer with num_classes output neurons\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Download the pretrained model and save it as keras layer\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m feature_extractor_layer \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m(model_url,trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,input_shape\u001b[38;5;241m=\u001b[39mIMAGE_SHAPE\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m3\u001b[39m,))\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     20\u001b[0m     feature_extractor_layer,\n\u001b[1;32m     21\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(num_classes,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m ])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_hub' has no attribute 'KerasLayer'"
     ]
    }
   ],
   "source": [
    "# Create resnet model\n",
    "resnet_model = create_model(resnet_url,10)\n",
    "resnet_model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084dea6-9cb6-40f1-adc7-e83aa3d7fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_history = resnet_model.fit(train_data_10_percent,\n",
    "                                  epochs=5,steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data),\n",
    "                                 callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",experiment_name=\"resnet50V2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bd685-7ab8-4d7d-afcd-88b9944a838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to plot our loss curves\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_graphs(title,plot1,plot2,label1,label2,xlabel,ylabel):\n",
    "    plt.title(title)\n",
    "    plt.plot(plot1,label=label1)\n",
    "    plt.plot(plot2,label=label2)\n",
    "    plt.xticks([1,2,3,4])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f109bd1-f482-40e3-87b9-0a2c2e5248a1",
   "metadata": {},
   "source": [
    "Wow!\n",
    "\n",
    "That. Is. Incredible. Our transfer learning feature extracting model out performed ALL of the previous models we built by hand... (substantially) and in a quicker training time AND with only 10% of the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cf8ff-31b3-4f10-b5bb-3c0f12e6aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(title=\"Training & Validation accuracy\",\n",
    "plot1=resnet_history.history[\"accuracy\"],\n",
    "plot2=resnet_history.history[\"val_accuracy\"],\n",
    "label1=\"Training Accuracy\",\n",
    "label2=\"Validation Accuracy\",\n",
    "xlabel=\"epochs\",\n",
    "ylabel=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae012d09-407f-4bac-964f-d7fe021766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(title=\"Validation & Training Loss\",\n",
    "plot1=resnet_history.history[\"loss\"],\n",
    "plot2=resnet_history.history[\"val_loss\"],\n",
    "label1=\"Training Loss\",\n",
    "label2=\"Validation Loss\",\n",
    "xlabel=\"epochs\",\n",
    "ylabel=\"percentage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01727f1a-44f4-4013-8e30-d6a5bee9b640",
   "metadata": {},
   "source": [
    "### Creating and testing EfficientNetB0 Tensorflow Hub model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a9943-db57-461b-a29c-4debe84ed2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resnet model\n",
    "efficientnet_model = create_model(efficientnet_url,10)\n",
    "efficientnet_model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
    "efficientnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09e70b-85b1-427c-a781-7965c7137295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details on efficient net - https://paperswithcode.com/method/efficientnet#:~:text=EfficientNet%20is%20a%20convolutional%20neural,resolution%20using%20a%20compound%20coefficient\n",
    "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
    "                                  epochs=10,steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data),\n",
    "                                 callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",experiment_name=\"efficientnetB0\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8378bcb-e963-4b4f-a0d5-ef5b11940c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(title=\"Training & Validation accuracy\",\n",
    "plot1=efficientnet_history.history[\"accuracy\"],\n",
    "plot2=efficientnet_history.history[\"val_accuracy\"],\n",
    "label1=\"Training Accuracy\",\n",
    "label2=\"Validation Accuracy\",\n",
    "xlabel=\"epochs\",\n",
    "ylabel=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c99bc-6632-4a41-8aae-fa45b7cdff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(title=\"Validation & Training Loss\",\n",
    "plot1=efficientnet_history.history[\"loss\"],\n",
    "plot2=efficientnet_history.history[\"val_loss\"],\n",
    "label1=\"Training Loss\",\n",
    "label2=\"Validation Loss\",\n",
    "xlabel=\"epochs\",\n",
    "ylabel=\"percentage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99240dbe-c50e-4289-a1a9-135f2dc70fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed512ae-4fc7-402c-bc23-2172ec6f0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208d3bb1-991a-4d90-a7a1-500ed17bbe07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efficientnet_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# How many layers does our efficientnetb0 feature extractor have?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mefficientnet_model\u001b[49m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweights)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'efficientnet_model' is not defined"
     ]
    }
   ],
   "source": [
    "# How many layers does our efficientnetb0 feature extractor have?\n",
    "len(efficientnet_model.layers[0].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ad73c-913e-403d-9c98-175b6f0623ab",
   "metadata": {},
   "source": [
    "## Different types of transfer learning\n",
    "\n",
    " * **\"As is\"** transfer learning - using existing model with no changes whatsoever(e.g using imagenet model on 1k imagenet classes)\n",
    " * **\"Feature extraction\"** transfer learning - using pretrained patterns of existing models(e.g efficient net b0 trained on imagenet) and adjust the output layer for your own purposes(e.g above using 1000 classes -> 10 classes of food)\n",
    " * **\"Fine-tuning\"** transfer learning - use the prelearned patterns of an existing model and \"fine-tune\" many or all of the underlying layers(including new output layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e2ccc-b6d2-460f-aa7b-fce7a26ef442",
   "metadata": {},
   "source": [
    "## Comparing our model results using Tensorboard\n",
    "\n",
    "**Note:** When you upload things to Tensorboard.dev, your experiments are public.\n",
    "\n",
    "**No longer applies with latest tensorboard it's hosted locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29abe1-41a5-4760-8c07-ab971234fd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-12 00:03:33.124284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-12 00:03:33.140350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-12 00:03:33.145231: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-12 00:03:33.156895: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726099414.197928     157 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726099414.205064     157 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726099414.206881     157 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# Upload Tensorboard dev records\n",
    "!tensorboard --logdir ./tensorflow_hub/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca94afd-fa35-43dc-b7e2-5429cef15661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout what tensorboard experiments you have - deprecated\n",
    "# !tensorboard dev list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c66d3-c267-4341-9579-6140aed9804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete experiment -deprecated\n",
    "# !tensorboard dev delete --experiment_id "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
